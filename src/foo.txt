----- FILE: app.py -----
import argparse
from datetime import datetime
import logging
import os
import json
from dotenv import load_dotenv
from services.audio.audio_service import AudioService
from services.audio.audio_downloader import AudioDownloader
from services.audio.file_handler import FileHandler
from services.transcription import TranscriptionServiceType, TranscriptionFactory

# Load environment variables from .env file
load_dotenv()

# Generate a log file name with the current date
log_filename = f"transcription_{datetime.now().strftime('%Y-%m-%d')}.log"

# Configure logging with the date in the file name
logging.basicConfig(filename=log_filename, level=logging.DEBUG, format='%(asctime)s %(levelname)s:%(message)s')

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Transcribe audio from a video or local file.')
    parser.add_argument('url', type=str, help='The URL of the video or path to the local file.')
    parser.add_argument('--path', type=str, default='./incoming', help='The directory path to save the audio file.')
    parser.add_argument('--max_length_minutes', type=int, default=None, help='Maximum length of the video in minutes.')
    parser.add_argument('--prompt', type=str, default=None, help='Prompt for the transcription service.')
    parser.add_argument('--service', type=str, choices=[service.value for service in TranscriptionServiceType], default='groq', help='The transcription service to use.')

    args = parser.parse_args()

    logging.debug("Processing audio...")

    if args.url.startswith("https://"):
        video_info = AudioDownloader.get_video_info(args.url)
        audio_file_path = AudioDownloader.download_audio(args.url, f'{args.path}/audio', max_length_minutes=args.max_length_minutes)
    else:
        video_info = {"title": os.path.basename(args.url), "duration": 0}
        audio_file_path = FileHandler.handle_local_file(args.url, args.path)

    logging.debug(f"Audio file is ready at {audio_file_path}")

    if audio_file_path is not None:
        logging.debug(f"Running transcription on {audio_file_path}")
        transcription_service = TranscriptionFactory.get_transcription_service(TranscriptionServiceType(args.service)) 
        combined_transcription = AudioService.transcribe_audio(audio_file_path, transcription_service, args.prompt)
        
        transcription_file_path = f'{os.path.splitext(audio_file_path)[0]}_transcript{transcription_service.file_name_extension()}'.replace("audio/", "transcript/")
        os.makedirs(os.path.dirname(transcription_file_path), exist_ok=True)
        
        with open(transcription_file_path, 'w', encoding='utf-8') as file:
            file.write(combined_transcription)

        # Adjust transcript if necessary
        combined_transcription, transcription_file_path = AudioService.adjust_transcript_if_needed(transcription_file_path, TranscriptionServiceType(args.service))

        result = {
            "url": args.url,
            "title": video_info.get("title", "Unknown Title"),
            "duration": video_info.get("duration", 0),
            "service": args.service,
            "transcription_file_path": transcription_file_path,  # Return adjusted file if applicable
            "transcript": combined_transcription  # Return the adjusted transcript text
        }

        os.remove(audio_file_path)

        print(json.dumps(result))


----- FILE: services/transcription/openai_transcription_service.py -----
import logging
from openai import OpenAI
from .transcription_service import TranscriptionService

class OpenAITranscriptionService(TranscriptionService):
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    def transcribe(self, audio_file_path: str, prompt: str) -> str:
        try:
            with open(audio_file_path, 'rb') as audio_file:
                logging.debug(f"Processing part {audio_file_path}")
                transcription = self.client.audio.transcriptions.create(model="whisper-1", file=audio_file, prompt=prompt)
            return transcription.text
        except Exception as e:
            logging.error(f"Error transcribing audio file: {e}")
            return ""

    def file_name_extension(self) -> str:
        return ".txt"


----- FILE: services/transcription/groq_transcription_service.py -----
import logging
from groq import Groq
from .transcription_service import TranscriptionService

class GroqTranscriptionService(TranscriptionService):
    def __init__(self, api_key: str):
        self.client = Groq(api_key=api_key)

    def transcribe(self, audio_file_path: str, prompt: str) -> str:
        try:
            with open(audio_file_path, 'rb') as audio_file:
                logging.debug(f"Processing part {audio_file_path}")
                trimmed_prompt = self.take_last_896_chars(prompt)
                transcription = self.client.audio.transcriptions.create(
                    model="whisper-large-v3", 
                    file=audio_file,
                    response_format="json"  # Correctly specify the response format here
                )
            return transcription.text
        except Exception as e:
            logging.error(f"Error transcribing audio file: {e}")
            return ""

    def file_name_extension(self) -> str:
        return ".txt"

    def take_last_896_chars(self, input_string):
        if len(input_string) > 896:
            return input_string[-896:]
        else:
            return input_string


----- FILE: services/transcription/__init__.py -----
from .transcription_service import TranscriptionService, TranscriptionServiceType
from .openai_transcription_service import OpenAITranscriptionService
from .openai_vtt_transcription_service import OpenAIVttTranscriptionService
from .openai_srt_transcription_service import OpenAISrtTranscriptionService
from .groq_transcription_service import GroqTranscriptionService
from .transcription_factory import TranscriptionFactory


----- FILE: services/transcription/transcription_factory.py -----
import os
from .transcription_service import TranscriptionService, TranscriptionServiceType
from .openai_transcription_service import OpenAITranscriptionService
from .openai_srt_transcription_service import OpenAISrtTranscriptionService
from .openai_vtt_transcription_service import OpenAIVttTranscriptionService
from .groq_transcription_service import GroqTranscriptionService

class TranscriptionFactory:
    _service_map = {
        TranscriptionServiceType.OPENAI: (OpenAITranscriptionService, "OPENAI_API_KEY"),
        TranscriptionServiceType.OPENAI_SRT: (OpenAISrtTranscriptionService, "OPENAI_API_KEY"),
        TranscriptionServiceType.OPENAI_VTT: (OpenAIVttTranscriptionService, "OPENAI_API_KEY"),
        TranscriptionServiceType.GROQ: (GroqTranscriptionService, "GROQ_API_KEY")
    }

    @staticmethod
    def get_transcription_service(service_name: TranscriptionServiceType) -> TranscriptionService:
        if service_name not in TranscriptionFactory._service_map:
            raise ValueError(f"Unsupported transcription service: {service_name}")

        service_class, api_key_env = TranscriptionFactory._service_map[service_name]
        api_key = os.getenv(api_key_env)
        if api_key is None:
            raise ValueError(f"{api_key_env} is not provided")

        return service_class(api_key)


----- FILE: services/transcription/openai_srt_transcription_service.py -----
import logging
from openai import OpenAI
from .transcription_service import TranscriptionService

class OpenAISrtTranscriptionService(TranscriptionService):
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    def transcribe(self, audio_file_path: str, prompt: str) -> str:
        try:
            with open(audio_file_path, 'rb') as audio_file:
                logging.debug(f"Processing part {audio_file_path}")
                transcription = self.client.audio.transcriptions.create(model="whisper-1", file=audio_file, response_format="srt", prompt=prompt)
            return transcription
        except Exception as e:
            logging.error(f"Error transcribing audio file: {e}")
            return ""

    def file_name_extension(self) -> str:
        return ".srt"


----- FILE: services/transcription/openai_vtt_transcription_service.py -----
import logging
from openai import OpenAI
from .transcription_service import TranscriptionService

class OpenAIVttTranscriptionService(TranscriptionService):
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    def transcribe(self, audio_file_path: str, prompt: str) -> str:
        try:
            with open(audio_file_path, 'rb') as audio_file:
                logging.debug(f"Processing part {audio_file_path}")
                transcription = self.client.audio.transcriptions.create(model="whisper-1", file=audio_file, response_format="vtt", prompt=prompt)
            return transcription
        except Exception as e:
            logging.error(f"Error transcribing audio file: {e}")
            return ""

    def file_name_extension(self) -> str:
        return ".vtt"


----- FILE: services/transcription/transcription_service.py -----
from abc import ABC, abstractmethod
from enum import Enum

class TranscriptionServiceType(Enum):
    OPENAI = "openai"
    OPENAI_VTT = "openai-vtt"
    OPENAI_SRT = "openai-srt"
    GROQ = "groq"

class TranscriptionService(ABC):
    @abstractmethod
    def transcribe(self, audio_file_path: str, prompt: str) -> str:
        pass

    def file_name_extension(self) -> str:
        pass


----- FILE: services/audio/file_handler.py -----
import os
import subprocess
import logging

class FileHandler:
    
    @staticmethod
    def handle_local_file(file_path: str, output_dir: str) -> str:
        file_name = os.path.basename(file_path)
        audio_file_path = os.path.join(output_dir, "audio", file_name)

        if not (file_name.endswith(".m4a") or file_name.endswith(".mp3")):
            logging.debug("Converting local file to audio...")
            file_name = file_name.replace(" ", "-")
            audio_file_path = os.path.join(output_dir, "audio", os.path.splitext(file_name)[0] + "_audio.m4a")
            os.makedirs(os.path.dirname(audio_file_path), exist_ok=True)
            subprocess.run(['ffmpeg', '-i', file_path, '-vn', '-ar', '16000', '-ac', '1', '-ab', '128k', '-f', 'ipod', audio_file_path], check=True)

        return audio_file_path


----- FILE: services/audio/srt_adjuster.py -----
import re
from datetime import timedelta

class SrtAdjuster:
    
    def __init__(self, srt_file, output_file):
        self.srt_file = srt_file
        self.output_file = output_file

    # Function to parse SRT time format
    def parse_srt_time(self, srt_time):
        hours, minutes, seconds = map(float, srt_time.replace(',', '.').split(':'))
        return timedelta(hours=int(hours), minutes=int(minutes), seconds=seconds)

    # Function to format time back to SRT format
    def format_srt_time(self, td):
        total_seconds = int(td.total_seconds())
        hours, remainder = divmod(total_seconds, 3600)
        minutes, seconds = divmod(remainder, 60)
        milliseconds = td.microseconds // 1000
        return f"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}"

    # Adjust timings in SRT file
    def adjust_timings(self):
        with open(self.srt_file, 'r', encoding='utf-8') as file:
            lines = file.readlines()

        adjusted_lines = []
        last_end_time = timedelta(0)
        last_segment_end_time = timedelta(0)
        time_pattern = re.compile(r"(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})")
        
        subtitle_number = 1
        for line in lines:
            match = time_pattern.match(line)
            if line.strip().isdigit():
                adjusted_lines.append(f"{subtitle_number}\n")
                subtitle_number += 1
            elif match:
                start_time, end_time = match.groups()
                start_time_td = self.parse_srt_time(start_time)
                end_time_td = self.parse_srt_time(end_time)

                if start_time_td < last_end_time:
                    last_segment_end_time = last_segment_end_time + last_end_time
                
                last_end_time = end_time_td
                start_time_td += last_segment_end_time
                end_time_td += last_segment_end_time

                adjusted_line = f"{self.format_srt_time(start_time_td)} --> {self.format_srt_time(end_time_td)}\n"
                adjusted_lines.append(adjusted_line)
            else:
                adjusted_lines.append(line)

        with open(self.output_file, 'w', encoding='utf-8') as file:
            file.writelines(adjusted_lines)


----- FILE: services/audio/vtt_adjuster.py -----
import re
from datetime import timedelta

class VttAdjuster:
    
    def __init__(self, vtt_file, output_file):
        self.vtt_file = vtt_file
        self.output_file = output_file

    # Function to parse VTT time format
    def parse_vtt_time(self, vtt_time):
        hours, minutes, seconds = map(float, vtt_time.replace(',', '.').split(':'))
        return timedelta(hours=int(hours), minutes=int(minutes), seconds=seconds)

    # Function to format time back to VTT format
    def format_vtt_time(self, td):
        total_seconds = int(td.total_seconds())
        hours, remainder = divmod(total_seconds, 3600)
        minutes, seconds = divmod(remainder, 60)
        milliseconds = td.microseconds // 1000
        return f"{hours:02}:{minutes:02}:{seconds:02}.{milliseconds:03}"

    # Adjust timings in VTT file
    def adjust_timings(self):
        with open(self.vtt_file, 'r', encoding='utf-8') as file:
            lines = file.readlines()

        adjusted_lines = []
        last_end_time = timedelta(0)
        last_segment_end_time = timedelta(0)
        time_pattern = re.compile(r"(\d{2}:\d{2}:\d{2}\.\d{3}) --> (\d{2}:\d{2}:\d{2}\.\d{3})")

        for line in lines:
            match = time_pattern.match(line)
            if match:
                start_time, end_time = match.groups()
                start_time_td = self.parse_vtt_time(start_time)
                end_time_td = self.parse_vtt_time(end_time)

                if start_time_td < last_end_time:
                    last_segment_end_time += last_end_time
                
                last_end_time = end_time_td
                start_time_td += last_segment_end_time
                end_time_td += last_segment_end_time

                adjusted_line = f"{self.format_vtt_time(start_time_td)} --> {self.format_vtt_time(end_time_td)}\n"
                adjusted_lines.append(adjusted_line)
            else:
                adjusted_lines.append(line)

        with open(self.output_file, 'w', encoding='utf-8') as file:
            file.writelines(adjusted_lines)


----- FILE: services/audio/audio_service.py -----
import os
import logging
from typing import List, Optional
from pydub import AudioSegment
from services.transcription import TranscriptionServiceType
from services.audio.srt_adjuster import SrtAdjuster
from services.audio.vtt_adjuster import VttAdjuster

class AudioService:
    
    @staticmethod
    def split_audio(file_path: str, segment_length_ms: int = 600000) -> List[str]:
        song = AudioSegment.from_file(file_path)
        parts = len(song) // segment_length_ms + 1
        base, ext = os.path.splitext(file_path)
        audio_format = ext.replace('.', '')

        segments = []
        for i in range(parts):
            start = i * segment_length_ms
            part = song[start:start + segment_length_ms]
            part_file_path = f"{base}_part{i}{ext}"
            if audio_format == 'm4a':
                part.export(part_file_path, format='ipod')
            else:
                part.export(part_file_path, format=audio_format)
            segments.append(part_file_path)
        
        return segments

    @staticmethod
    def transcribe_audio_segment(service, audio_file_path: str, prompt: str) -> str:
        try:
            # Making the transcription API call
            with open(audio_file_path, 'rb') as audio_file:
                logging.debug(f"Processing part {audio_file_path}")
                transcription = service.client.audio.transcriptions.create(
                    model="whisper-1", 
                    file=audio_file, 
                    prompt=prompt,
                    response_format=service.file_name_extension().lstrip('.')
                )
                # Handle the response as plain text
                transcription_text = transcription
        except Exception as e:
            logging.error(f"Error transcribing audio file: {e}")
            transcription_text = ""
        
        return transcription_text

    @staticmethod
    def transcribe_audio(file_path: str, service, prompt: str) -> str:
        if os.path.getsize(file_path) > 26214400:  # If file size exceeds 25MB
            transcriptions: List[str] = []
            system_prompt = prompt
            for segment_path in AudioService.split_audio(file_path):
                transcription = AudioService.transcribe_audio_segment(service, segment_path, system_prompt)
                system_prompt = f"{transcription} {prompt}"
                transcriptions.append(transcription)
                os.remove(segment_path)
            return ' '.join(transcriptions)
        else:
            return AudioService.transcribe_audio_segment(service, file_path, prompt)

    @staticmethod
    def adjust_transcript_if_needed(transcription_file_path: str, service_type: TranscriptionServiceType) -> str:
        if service_type == TranscriptionServiceType.OPENAI_SRT:
            adjusted_srt_file_path = transcription_file_path.replace(".srt", "_adjusted.srt")
            srt_adjuster = SrtAdjuster(transcription_file_path, adjusted_srt_file_path)
            srt_adjuster.adjust_timings()
            with open(adjusted_srt_file_path, 'r', encoding='utf-8') as file:
                return file.read(), adjusted_srt_file_path

        elif service_type == TranscriptionServiceType.OPENAI_VTT:
            adjusted_vtt_file_path = transcription_file_path.replace(".vtt", "_adjusted.vtt")
            vtt_adjuster = VttAdjuster(transcription_file_path, adjusted_vtt_file_path)
            vtt_adjuster.adjust_timings()
            with open(adjusted_vtt_file_path, 'r', encoding='utf-8') as file:
                return file.read(), adjusted_vtt_file_path

        # If no adjustment was needed, just return the original transcript
        with open(transcription_file_path, 'r', encoding='utf-8') as file:
            return file.read(), transcription_file_path


----- FILE: services/audio/audio_downloader.py -----
import json
import os
import re
import subprocess
import logging
from typing import Optional

class AudioDownloader:
    
    @staticmethod
    def get_video_info(url: str) -> dict:
        command = [
            'yt-dlp',
            '--dump-json',
            url
        ]
        result = subprocess.run(command, check=True, capture_output=True, text=True)
        video_info = result.stdout
        return json.loads(video_info)

    @staticmethod
    def download_audio(url: str, path: str, max_length_minutes: Optional[int] = None) -> Optional[str]:
        logging.debug(f"Downloading audio from {url} to {path}")
        current_directory = os.getcwd()
        logging.debug(f"Current Directory: {current_directory}")

        if not os.path.exists(path):
            os.makedirs(path)

        command = [
            'yt-dlp',
            '-x',  # Extract audio
            '--audio-format', 'm4a',  # Specify audio format
            '--output', os.path.join(path, '%(title)s.%(ext)s'),  # Naming convention
            '--format', 'bestaudio',
            '-N', '4',  # use 4 connections
            url  # YouTube URL
        ]

        try:
            result = subprocess.run(command, check=True, capture_output=True, text=True)
            output = result.stdout
            logging.debug(f"yt-dlp output: {output}")
            file_path_match = re.search(r'Destination:\s+(.*\.m4a)', output)
            
            if file_path_match:
                file_path = file_path_match.group(1).strip()
                logging.debug(f"File path found: {file_path}")
                if os.path.exists(file_path) and file_path.endswith(".m4a"):
                    logging.debug(f"File exists: {file_path}")
                    if max_length_minutes:
                        logging.debug(f"Trimming audio file: {file_path}")
                        max_length_seconds = max_length_minutes * 60
                        trimmed_file_path = file_path.replace('.m4a', '_trimmed.m4a')
                        subprocess.run(['ffmpeg', '-i', file_path, '-ss', '00:00:00', '-t', str(max_length_seconds), trimmed_file_path], check=True)
                        os.remove(file_path)
                        return trimmed_file_path
                    return file_path
                else:
                    logging.error(f"File does not exist or is not a .m4a file: {file_path}")
            else:
                logging.error("File path not found in yt-dlp output")
        except subprocess.CalledProcessError as e:
            logging.error(f"Error: {e.stderr}")
        
        return None


