----- FILE: tests/conftest.py -----
import sys
import os

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))


----- FILE: tests/test_audio_downloader.py -----
import pytest
from unittest.mock import patch, MagicMock, call
from services.audio.audio_downloader import AudioDownloader

def test_get_video_info(mocker):
    mock_subprocess = mocker.patch('subprocess.run')
    mock_subprocess.return_value.stdout = '{"title": "Test Video", "duration": 120}'

    result = AudioDownloader.get_video_info('https://www.youtube.com/watch?v=abc123')
    
    assert result['title'] == "Test Video"
    assert result['duration'] == 120

def test_download_audio(mocker):
    mock_subprocess = mocker.patch('subprocess.run')
    mock_subprocess.return_value.stdout = 'Destination: /fake/path/to/audio.m4a'
    mocker.patch('os.makedirs')  # Mock os.makedirs to avoid filesystem access
    mocker.patch('os.path.exists', return_value=True)  # Mock os.path.exists to always return True

    result = AudioDownloader.download_audio('https://www.youtube.com/watch?v=abc123', '/fake/path')
    
    assert result == '/fake/path/to/audio.m4a'
    mock_subprocess.assert_called_once_with(
        [
            'yt-dlp',
            '-x',  # Extract audio
            '--audio-format', 'm4a',  # Specify audio format
            '--output', '/fake/path/%(title)s.%(ext)s',  # Naming convention
            '--format', 'bestaudio',
            '-N', '4',  # use 4 connections
            'https://www.youtube.com/watch?v=abc123'
        ],
        check=True, capture_output=True, text=True
    )

def test_download_google_drive_video(mocker):
    mock_subprocess = mocker.patch('subprocess.run')
    
    # Mock the first subprocess call for yt-dlp
    mock_subprocess.side_effect = [
        mocker.Mock(stdout='Destination: /fake/path/google/video.mp4'),
        mocker.Mock()  # Mock for the second call (ffmpeg)
    ]
    
    # Mock all relevant file system operations
    mocker.patch('os.makedirs')  # Mock directory creation
    mocker.patch('os.path.exists', return_value=True)  # Mock path existence checks
    mocker.patch('os.listdir', return_value=['video.mp4'])  # Mock file listing
    mocker.patch('os.remove')  # Mock os.remove to prevent actual file deletion
    
    result = AudioDownloader.download_google_drive_video('https://drive.google.com/file/d/abc123/view', '/fake/path')

    # Verify the expected output
    assert result == "/fake/path/audio/video_audio.m4a"
    
    # Verify both subprocess calls
    mock_subprocess.assert_has_calls([
        mocker.call(
            [
                'yt-dlp',
                '--output', '/fake/path/google/%(title)s.%(ext)s',  # Naming convention
                '--format', 'bestvideo+bestaudio/best',  # Download best video and audio format available
                'https://drive.google.com/uc?export=download&id=abc123'
            ],
            check=True, capture_output=True, text=True
        ),
        mocker.call(
            [
                'ffmpeg',
                '-i', '/fake/path/google/video.mp4',
                '-vn', '-ar', '16000',
                '-ac', '1', '-ab', '128k',
                '-f', 'mp4', '/fake/path/audio/video_audio.m4a'
            ],
            check=True
        )
    ])


----- FILE: tests/test_audio_service.py -----
import pytest
from unittest.mock import mock_open, patch, MagicMock
from services.audio.audio_service import AudioService

def test_transcribe_audio(mocker):
    # Mock the transcribe_audio_segment method within AudioService
    mocker.patch('services.audio.audio_service.AudioService.transcribe_audio_segment', return_value="Transcribed text")

    # Mock the file size and file access
    mocker.patch('os.path.getsize', return_value=1024)  # Mock file size less than 25MB
    mocker.patch('builtins.open', mock_open(read_data="mocked file content"))  # Mock file access

    # Perform the test
    result = AudioService.transcribe_audio('path/to/audio.m4a', MagicMock(), 'test prompt')

    # Verify that the result is as expected
    assert result == "Transcribed text"

def test_split_audio(mocker):
    mock_pydub = mocker.patch('services.audio.audio_service.AudioSegment.from_file')
    mock_audio_segment = MagicMock()
    mock_audio_segment.__len__.return_value = 1200000  # 20 minutes of audio (1,200,000 ms)
    mock_pydub.return_value = mock_audio_segment

    result = AudioService.split_audio('path/to/audio.m4a', segment_length_ms=600000)

    assert len(result) == 2  # Adjust this expectation based on your real logic or mock duration
    assert "part0.m4a" in result[0]
    assert "part1.m4a" in result[1]


----- FILE: tests/test_app.py -----
import pytest
from unittest.mock import patch, MagicMock
import sys
import json
from app import main

def test_main_with_youtube_url(mocker):
    mock_get_video_info = mocker.patch('services.audio.audio_downloader.AudioDownloader.get_video_info', return_value={"title": "Test Video", "duration": 120})
    mock_download_audio = mocker.patch('services.audio.audio_downloader.AudioDownloader.download_audio', return_value="path/to/audio.m4a")
    mock_transcribe_audio = mocker.patch('services.audio.audio_service.AudioService.transcribe_audio', return_value="Transcribed text")
    mock_remove = mocker.patch('os.remove')
    
    expected_output = {
        "url": "https://www.youtube.com/watch?v=abc123",
        "title": "Test Video",
        "duration": 120,
        "service": "groq",
        "transcription_file_path": "path/to/audio_transcript.txt",
        "transcript": "Transcribed text"
    }
    
    test_args = ["app.py", "https://www.youtube.com/watch?v=abc123", "--path", "/fake/path"]
    with patch.object(sys, 'argv', test_args):
        with patch('builtins.print') as mock_print:
            main()

            mock_print.assert_called_once_with(json.dumps(expected_output))
    
    mock_get_video_info.assert_called_once()
    mock_download_audio.assert_called_once()
    mock_transcribe_audio.assert_called_once()
    mock_remove.assert_called_once_with("path/to/audio.m4a")


----- FILE: app.py -----
import argparse
from datetime import datetime
import logging
import os
import json
from dotenv import load_dotenv
from services.audio.audio_service import AudioService
from services.audio.audio_downloader import AudioDownloader
from services.audio.file_handler import FileHandler
from services.transcription import TranscriptionServiceType, TranscriptionFactory
from pydub import AudioSegment

from services.transformation import TranscriptionTransformation
from services.transformation.transformation_factory import TransformationFactory

def get_audio_duration(file_path: str) -> int:
    audio = AudioSegment.from_file(file_path)
    duration_seconds = len(audio) / 1000  # pydub returns length in milliseconds
    return duration_seconds

def main():
    # Load environment variables from .env file
    load_dotenv()

    # Create logs directory if it doesn't exist
    logs_dir = 'logs'
    os.makedirs(logs_dir, exist_ok=True)

    # Generate a log file name with the current date
    log_filename = os.path.join(logs_dir, f"transcription_{datetime.now().strftime('%Y-%m-%d')}.log")

    # Configure logging with the date in the file name
    logging.basicConfig(filename=log_filename, level=logging.DEBUG, format='%(asctime)s %(levelname)s:%(message)s')

    parser = argparse.ArgumentParser(description='Transcribe audio from a video or local file.')
    parser.add_argument('url', type=str, help='The URL of the video or path to the local file.')
    parser.add_argument('--transform', type=str, choices=[transform.value for transform in TranscriptionTransformation], default='none', help='The transform to perform on the transcript.')
    parser.add_argument('--path', type=str, default='./incoming', help='The directory path to save the audio file.')
    parser.add_argument('--max_length_minutes', type=int, default=None, help='Maximum length of the video in minutes.')
    parser.add_argument('--prompt', type=str, default=None, help='Prompt for the transcription service.')
    parser.add_argument('--service', type=str, choices=[service.value for service in TranscriptionServiceType], default='groq', help='The transcription service to use.')

    args = parser.parse_args()

    logging.info("Processing audio...")

    if args.url.startswith("https://drive.google.com"):
        audio_file_path = AudioDownloader.download_google_drive_video(args.url, args.path, max_length_minutes=args.max_length_minutes)
        video_info = {"title": "Google Drive Video", "duration": get_audio_duration(audio_file_path)}  # Google Drive doesn't give video info easily
    elif "vimeo.com" in args.url:
        video_info = AudioDownloader.get_video_info(args.url)
        audio_file_path = AudioDownloader.download_vimeo_video(args.url, f'{args.path}/audio', max_length_minutes=args.max_length_minutes)
    elif args.url.startswith("https://"):
        video_info = AudioDownloader.get_video_info(args.url)
        audio_file_path = AudioDownloader.download_audio(args.url, f'{args.path}/audio', max_length_minutes=args.max_length_minutes)
    else:
        logging.info("Processing file...")
        audio_file_path = FileHandler.handle_local_file(args.url, args.path)
        video_info = {"title": os.path.basename(args.url), "duration": get_audio_duration(audio_file_path)}

    logging.info(f"Audio file is ready at {audio_file_path}")

    if audio_file_path is not None:
        logging.info(f"Running transcription on {audio_file_path}")
        transcription_service = TranscriptionFactory.get_transcription_service(TranscriptionServiceType(args.service)) 
        combined_transcription = AudioService.transcribe_audio(audio_file_path, transcription_service, args.prompt)
        
        transcription_file_path = f'{os.path.splitext(audio_file_path)[0]}_transcript{transcription_service.file_name_extension()}'.replace("audio/", "transcript/")
        os.makedirs(os.path.dirname(transcription_file_path), exist_ok=True)
        
        logging.info(f"Writing transcript to {transcription_file_path}")
        with open(transcription_file_path, 'w', encoding='utf-8') as file:
            file.write(combined_transcription)

        try:
            # Adjust transcript if necessary
            logging.info("Adjusting transcript timings if needed...")
            combined_transcription, transcription_file_path = AudioService.adjust_transcript_if_needed(transcription_file_path, TranscriptionServiceType(args.service))

            # Run the transformation
            logging.info(f"Running transformation {args.transform}")
            # build metadata
            metadata = {
                "duration" : video_info.get("duration", 0), # used for youtube highlights
                "length" : 3000, # used for youtube summary
            }
            logging.info(f"Metadata: {metadata} for transformation {args.transform}")
            transformation = TransformationFactory.get_transformation_service(TranscriptionTransformation(args.transform))
            transformed_transcript = transformation.transform(combined_transcription, metadata=metadata)
        except Exception as e:
            logging.error(f"An error occurred during transcript adjustment or transformation: {str(e)}")
            print(json.dumps({"error": f"An error occurred: {str(e)}"}))
            raise
        finally:
            os.remove(audio_file_path)

        result = {
            "url": args.url,
            "title": video_info.get("title", "Unknown Title"),
            "duration": video_info.get("duration", 0),
            "service": args.service,
            "transcription_file_path": transcription_file_path,
            "transcript": combined_transcription,
            "transformed_transcript": transformed_transcript,
            "transform": args.transform
        }

        

        print(json.dumps(result))

if __name__ == "__main__":
    main()


----- FILE: services/transcription/openai_transcription_service.py -----
import logging
from openai import OpenAI
from .transcription_service import TranscriptionService

class OpenAITranscriptionService(TranscriptionService):
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    def transcribe(self, audio_file_path: str, prompt: str) -> str:
        try:
            with open(audio_file_path, 'rb') as audio_file:
                logging.debug(f"Processing part {audio_file_path}")
                transcription = self.client.audio.transcriptions.create(model="whisper-1", file=audio_file, response_format="json", prompt=prompt)
            return transcription.text
        except Exception as e:
            logging.error(f"Error transcribing audio file: {e}")
            return ""

    def file_name_extension(self) -> str:
        return ".txt"


----- FILE: services/transcription/groq_transcription_service.py -----
import logging
from groq import Groq
from .transcription_service import TranscriptionService

class GroqTranscriptionService(TranscriptionService):
    def __init__(self, api_key: str):
        self.client = Groq(api_key=api_key)

    def transcribe(self, audio_file_path: str, prompt: str) -> str:
        try:
            with open(audio_file_path, 'rb') as audio_file:
                logging.debug(f"Processing part {audio_file_path}")
                trimmed_prompt = self.take_last_896_chars(prompt)
                transcription = self.client.audio.transcriptions.create(
                    model="whisper-large-v3", 
                    file=audio_file,
                    response_format="json"  # Correctly specify the response format here
                )
            return transcription.text
        except Exception as e:
            logging.error(f"Error transcribing audio file: {e}")
            return ""

    def file_name_extension(self) -> str:
        return ".txt"

    def take_last_896_chars(self, input_string):
        if len(input_string) > 896:
            return input_string[-896:]
        else:
            return input_string


----- FILE: services/transcription/__init__.py -----
from .transcription_service import TranscriptionService, TranscriptionServiceType
from .openai_transcription_service import OpenAITranscriptionService
from .openai_vtt_transcription_service import OpenAIVttTranscriptionService
from .openai_srt_transcription_service import OpenAISrtTranscriptionService
from .groq_transcription_service import GroqTranscriptionService
from .transcription_factory import TranscriptionFactory


----- FILE: services/transcription/transcription_factory.py -----
import os
from .transcription_service import TranscriptionService, TranscriptionServiceType
from .openai_transcription_service import OpenAITranscriptionService
from .openai_srt_transcription_service import OpenAISrtTranscriptionService
from .openai_vtt_transcription_service import OpenAIVttTranscriptionService
from .groq_transcription_service import GroqTranscriptionService

class TranscriptionFactory:
    _service_map = {
        TranscriptionServiceType.OPENAI: (OpenAITranscriptionService, "OPENAI_API_KEY"),
        TranscriptionServiceType.OPENAI_SRT: (OpenAISrtTranscriptionService, "OPENAI_API_KEY"),
        TranscriptionServiceType.OPENAI_VTT: (OpenAIVttTranscriptionService, "OPENAI_API_KEY"),
        TranscriptionServiceType.GROQ: (GroqTranscriptionService, "GROQ_API_KEY")
    }

    @staticmethod
    def get_transcription_service(service_name: TranscriptionServiceType) -> TranscriptionService:
        if service_name not in TranscriptionFactory._service_map:
            raise ValueError(f"Unsupported transcription service: {service_name}")

        service_class, api_key_env = TranscriptionFactory._service_map[service_name]
        api_key = os.getenv(api_key_env)
        if api_key is None:
            raise ValueError(f"{api_key_env} is not provided")

        return service_class(api_key)


----- FILE: services/transcription/openai_srt_transcription_service.py -----
import logging
from openai import OpenAI
from .transcription_service import TranscriptionService

class OpenAISrtTranscriptionService(TranscriptionService):
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    def transcribe(self, audio_file_path: str, prompt: str) -> str:
        try:
            with open(audio_file_path, 'rb') as audio_file:
                logging.debug(f"Processing part {audio_file_path}")
                transcription = self.client.audio.transcriptions.create(model="whisper-1", file=audio_file, response_format="srt", prompt=prompt)
            return transcription
        except Exception as e:
            logging.error(f"Error transcribing audio file: {e}")
            return ""

    def file_name_extension(self) -> str:
        return ".srt"


----- FILE: services/transcription/openai_vtt_transcription_service.py -----
import logging
from openai import OpenAI
from .transcription_service import TranscriptionService

class OpenAIVttTranscriptionService(TranscriptionService):
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    def transcribe(self, audio_file_path: str, prompt: str) -> str:
        try:
            with open(audio_file_path, 'rb') as audio_file:
                logging.debug(f"Processing part {audio_file_path}")
                transcription = self.client.audio.transcriptions.create(model="whisper-1", file=audio_file, response_format="vtt", prompt=prompt)
            return transcription
        except Exception as e:
            logging.error(f"Error transcribing audio file: {e}")
            return ""

    def file_name_extension(self) -> str:
        return ".vtt"


----- FILE: services/transcription/transcription_service.py -----
from abc import ABC, abstractmethod
from enum import Enum

class TranscriptionServiceType(Enum):
    OPENAI = "openai"
    OPENAI_VTT = "openai-vtt"
    OPENAI_SRT = "openai-srt"
    GROQ = "groq"

class TranscriptionService(ABC):
    @abstractmethod
    def transcribe(self, audio_file_path: str, prompt: str) -> str:
        pass

    def file_name_extension(self) -> str:
        pass


----- FILE: services/transformation/none.py -----

from .transformation_service import TransformationService

class NoneTransformation(TransformationService):
    def transform(self, transcript: str) -> str:
        return transcript

----- FILE: services/transformation/paragraphs.py -----
from openai import OpenAI
from langchain import hub
from .transformation_service import TransformationService

class FormattingForParagraphsTransformation(TransformationService):
    def __init__(self, openai_api_key: str, lang_smith_api_key: str):
        self.llmOpsKey = lang_smith_api_key
        self.client = OpenAI(api_key=openai_api_key)
        
    def transform(self, transcript: str, metadata: dict) -> str:
        chain = hub.pull("scribe-ai-format-for-paragraphs", include_model=True, api_key=self.llmOpsKey)
        summary = chain.invoke({"transcript": transcript})
        return summary.content

----- FILE: services/transformation/youtubesummary.py -----
from openai import OpenAI
from langchain import hub
from .transformation_service import TransformationService

class FormattingForYoutubeSummaryTransformation(TransformationService):
    def __init__(self, openai_api_key: str, lang_smith_api_key: str):
        self.llmOpsKey = lang_smith_api_key
        self.client = OpenAI(api_key=openai_api_key)
        
    def transform(self, transcript: str, metadata: dict) -> str:
        chain = hub.pull("scribe-ai-format-3000char-summary", include_model=True, api_key=self.llmOpsKey)
        summary = chain.invoke({"transcript": transcript, "length": metadata.get("length", 3000)})
        return summary.content

----- FILE: services/transformation/keywords.py -----
from openai import OpenAI
from langchain import hub
from .transformation_service import TransformationService

class FormattingForKeywordsTransformation(TransformationService):
    def __init__(self, openai_api_key: str, lang_smith_api_key: str):
        self.llmOpsKey = lang_smith_api_key
        self.client = OpenAI(api_key=openai_api_key)
        
    def transform(self, transcript: str, metadata: dict) -> str:
        chain = hub.pull("scribe-ai-format-for-keywords", include_model=True, api_key=self.llmOpsKey)
        summary = chain.invoke({"transcript": transcript})
        return summary.content

----- FILE: services/transformation/__init__.py -----
from .transformation_service import TranscriptionTransformation
from .transformation_factory import TransformationFactory
from .none import NoneTransformation
from .summarize import SummarizeTransformation

----- FILE: services/transformation/summarize.py -----
from openai import OpenAI
from langchain import hub
from .transformation_service import TransformationService

class SummarizeTransformation(TransformationService):
    def __init__(self, openai_api_key: str, lang_smith_api_key: str):
        self.llmOpsKey = lang_smith_api_key
        self.client = OpenAI(api_key=openai_api_key)
        
    def transform(self, transcript: str, metadata: dict) -> str:
        chain = hub.pull("scribe-ai-summary", include_model=True, api_key=self.llmOpsKey)
        summary = chain.invoke({"transcript": transcript})
        return summary.content

----- FILE: services/transformation/formatting.py -----
from openai import OpenAI
from langsmith import Client
from langchain import hub
from .transformation_service import TransformationService

class FormattingForReadabilityTransformation(TransformationService):
    def __init__(self, openai_api_key: str, lang_smith_api_key: str):
        self.llmOpsKey = lang_smith_api_key
        self.client = OpenAI(api_key=openai_api_key)
        
    def transform(self, transcript: str, metadata: dict) -> str:
        chain = hub.pull("scribe-ai-format-for-readability", include_model=True, api_key=self.llmOpsKey)
        summary = chain.invoke({"transcript": transcript})
        return summary.content

----- FILE: services/transformation/youtubehighlights.py -----
from openai import OpenAI
from langsmith import Client
from langchain import hub
from .transformation_service import TransformationService

class FormattingForYoutubeHighlightsTransformation(TransformationService):
    def __init__(self, openai_api_key: str, lang_smith_api_key: str):
        self.llmOpsKey = lang_smith_api_key
        self.client = OpenAI(api_key=openai_api_key)
        
    def transform(self, transcript: str, metadata: dict) -> str:
        chain = hub.pull("scribe-ai-format-youtube-highlights-v2", include_model=True, api_key=self.llmOpsKey)
        summary = chain.invoke({"transcript": transcript, "duration": self.format_duration(metadata.get("duration", 0))})
        return summary.content
    
    def format_duration(self, seconds: int) -> str:
        h = seconds // 3600
        m = (seconds % 3600) // 60
        s = seconds % 60

        time_string = ':'.join(f'{unit:02}' for unit in (h, m, s))

        if h > 0:
            return f"{time_string} hours"
        elif m > 0:
            return f"{time_string} minutes"
        else:
            return f"{time_string} seconds"


----- FILE: services/transformation/removefillerwords.py -----
from openai import OpenAI
from langsmith import Client
from langchain import hub
from .transformation_service import TransformationService

class FormattingForFillerWordsTransformation(TransformationService):
    def __init__(self, openai_api_key: str, lang_smith_api_key: str):
        self.llmOpsKey = lang_smith_api_key
        self.client = OpenAI(api_key=openai_api_key)
        
    def transform(self, transcript: str, metadata: dict) -> str:
        chain = hub.pull("scribe-ai-format-for-filler-words", include_model=True, api_key=self.llmOpsKey)
        summary = chain.invoke({"transcript": transcript})
        return summary.content

----- FILE: services/transformation/transformation_service.py -----
from abc import ABC, abstractmethod
from enum import Enum

class TranscriptionTransformation(Enum):
    NONE = "none"
    SUMMARIZE = "summarize"
    FORMATTING = "formatting"
    REMOVEFILLERWORDS = "removefillerwords"
    PARAGRAPHS = "paragraphs"
    KEYWORDS = "keywords"
    YOUTUBEHIGHLIGHTS = "youtubehighlights"
    YOUTUBESUMMARY = "youtubesummary"
    TRANSLATION = "translation"
    IMAGE = "image"

class TransformationService(ABC):
    @abstractmethod
    def transform(self, transcript: str, metadata: dict = None) -> str:
        pass


----- FILE: services/transformation/transformation_factory.py -----
import os

from .formatting import FormattingForReadabilityTransformation
from .keywords import FormattingForKeywordsTransformation
from .paragraphs import FormattingForParagraphsTransformation
from .removefillerwords import FormattingForFillerWordsTransformation
from .youtubehighlights import FormattingForYoutubeHighlightsTransformation
from .youtubesummary import FormattingForYoutubeSummaryTransformation
from .none import NoneTransformation
from .summarize import SummarizeTransformation
from .transformation_service import TranscriptionTransformation, TransformationService


class TransformationFactory:
    _service_map = {
        TranscriptionTransformation.NONE: (NoneTransformation, None, None),
        TranscriptionTransformation.SUMMARIZE: (SummarizeTransformation, "OPENAI_API_KEY", "LANGCHAIN_API_KEY"),
        TranscriptionTransformation.FORMATTING: (FormattingForReadabilityTransformation, "OPENAI_API_KEY", "LANGCHAIN_API_KEY"),
        TranscriptionTransformation.PARAGRAPHS: (FormattingForParagraphsTransformation, "OPENAI_API_KEY", "LANGCHAIN_API_KEY"),
        TranscriptionTransformation.REMOVEFILLERWORDS: (FormattingForFillerWordsTransformation, "OPENAI_API_KEY", "LANGCHAIN_API_KEY"),
        TranscriptionTransformation.KEYWORDS: (FormattingForKeywordsTransformation, "OPENAI_API_KEY", "LANGCHAIN_API_KEY"),
        TranscriptionTransformation.YOUTUBEHIGHLIGHTS : (FormattingForYoutubeHighlightsTransformation, "OPENAI_API_KEY", "LANGCHAIN_API_KEY"),
        TranscriptionTransformation.YOUTUBESUMMARY : (FormattingForYoutubeSummaryTransformation, "OPENAI_API_KEY", "LANGCHAIN_API_KEY"),
    }

    @staticmethod
    def get_transformation_service(service_name: TranscriptionTransformation) -> TransformationService:
        if service_name not in TransformationFactory._service_map:
            raise ValueError(f"Unsupported transcription service: {service_name}")

        service_class, *api_key_envs = TransformationFactory._service_map[service_name]
        api_keys = [os.getenv(key) for key in api_key_envs if key]
        if any(key is None for key in api_keys):
            missing_keys = [key for key, value in zip(api_key_envs, api_keys) if value is None]
            raise ValueError(f"API keys missing: {', '.join(missing_keys)}")

        return service_class(*api_keys)



----- FILE: services/audio/file_handler.py -----
import os
import subprocess
import logging

class FileHandler:
    
    @staticmethod
    def handle_local_file(file_path: str, output_dir: str) -> str:
        file_name = os.path.basename(file_path)
        base_name, ext = os.path.splitext(file_name)
        audio_file_path = os.path.join(output_dir, "audio", base_name + "_audio.m4a")

        # Check for video formats that need conversion to audio
        if ext.lower() in [".mov", ".mp4", ".avi", ".mkv", ".webm"]:
            logging.debug(f"Converting video file {file_name} to audio and saving to {audio_file_path}")
            os.makedirs(os.path.dirname(audio_file_path), exist_ok=True)
            subprocess.run(['ffmpeg', '-i', file_path, '-vn', '-ar', '16000', '-ac', '1', '-ab', '128k', '-f', 'ipod', audio_file_path], check=True)
        elif ext.lower() not in [".m4a", ".mp3"]:
            logging.debug(f"Converting unsupported audio file {file_name} to m4a...")
            os.makedirs(os.path.dirname(audio_file_path), exist_ok=True)
            subprocess.run(['ffmpeg', '-i', file_path, '-vn', '-ar', '16000', '-ac', '1', '-ab', '128k', '-f', 'ipod', audio_file_path], check=True)
        else:
            logging.debug(f"No conversion needed for file {file_name}, copying to output directory...")
            os.makedirs(os.path.dirname(audio_file_path), exist_ok=True)
            subprocess.run(['cp', file_path, audio_file_path])

        return audio_file_path


----- FILE: services/audio/srt_adjuster.py -----
import re
from datetime import timedelta

class SrtAdjuster:
    
    def __init__(self, srt_file, output_file):
        self.srt_file = srt_file
        self.output_file = output_file

    # Function to parse SRT time format
    def parse_srt_time(self, srt_time):
        hours, minutes, seconds = map(float, srt_time.replace(',', '.').split(':'))
        return timedelta(hours=int(hours), minutes=int(minutes), seconds=seconds)

    # Function to format time back to SRT format
    def format_srt_time(self, td):
        total_seconds = int(td.total_seconds())
        hours, remainder = divmod(total_seconds, 3600)
        minutes, seconds = divmod(remainder, 60)
        milliseconds = td.microseconds // 1000
        return f"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}"

    # Adjust timings in SRT file
    def adjust_timings(self):
        with open(self.srt_file, 'r', encoding='utf-8') as file:
            lines = file.readlines()

        adjusted_lines = []
        last_end_time = timedelta(0)
        last_segment_end_time = timedelta(0)
        time_pattern = re.compile(r"(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})")
        
        subtitle_number = 1
        for line in lines:
            match = time_pattern.match(line)
            if line.strip().isdigit():
                adjusted_lines.append(f"{subtitle_number}\n")
                subtitle_number += 1
            elif match:
                start_time, end_time = match.groups()
                start_time_td = self.parse_srt_time(start_time)
                end_time_td = self.parse_srt_time(end_time)

                if start_time_td < last_end_time:
                    last_segment_end_time = last_segment_end_time + last_end_time
                
                last_end_time = end_time_td
                start_time_td += last_segment_end_time
                end_time_td += last_segment_end_time

                adjusted_line = f"{self.format_srt_time(start_time_td)} --> {self.format_srt_time(end_time_td)}\n"
                adjusted_lines.append(adjusted_line)
            else:
                adjusted_lines.append(line)

        with open(self.output_file, 'w', encoding='utf-8') as file:
            file.writelines(adjusted_lines)


----- FILE: services/audio/vtt_adjuster.py -----
import re
from datetime import timedelta

class VttAdjuster:
    
    def __init__(self, vtt_file, output_file):
        self.vtt_file = vtt_file
        self.output_file = output_file

    # Function to parse VTT time format
    def parse_vtt_time(self, vtt_time):
        hours, minutes, seconds = map(float, vtt_time.replace(',', '.').split(':'))
        return timedelta(hours=int(hours), minutes=int(minutes), seconds=seconds)

    # Function to format time back to VTT format
    def format_vtt_time(self, td):
        total_seconds = int(td.total_seconds())
        hours, remainder = divmod(total_seconds, 3600)
        minutes, seconds = divmod(remainder, 60)
        milliseconds = td.microseconds // 1000
        return f"{hours:02}:{minutes:02}:{seconds:02}.{milliseconds:03}"

    # Adjust timings in VTT file
    def adjust_timings(self):
        with open(self.vtt_file, 'r', encoding='utf-8') as file:
            lines = file.readlines()

        adjusted_lines = []
        last_end_time = timedelta(0)
        last_segment_end_time = timedelta(0)
        time_pattern = re.compile(r"(\d{2}:\d{2}:\d{2}\.\d{3}) --> (\d{2}:\d{2}:\d{2}\.\d{3})")

        for line in lines:
            match = time_pattern.match(line)
            if match:
                start_time, end_time = match.groups()
                start_time_td = self.parse_vtt_time(start_time)
                end_time_td = self.parse_vtt_time(end_time)

                if start_time_td < last_end_time:
                    last_segment_end_time += last_end_time
                
                last_end_time = end_time_td
                start_time_td += last_segment_end_time
                end_time_td += last_segment_end_time

                adjusted_line = f"{self.format_vtt_time(start_time_td)} --> {self.format_vtt_time(end_time_td)}\n"
                adjusted_lines.append(adjusted_line)
            else:
                adjusted_lines.append(line)

        with open(self.output_file, 'w', encoding='utf-8') as file:
            file.writelines(adjusted_lines)


----- FILE: services/audio/audio_service.py -----
import os
import logging
from typing import List
from pydub import AudioSegment
from concurrent.futures import ThreadPoolExecutor, as_completed
from services.transcription import TranscriptionServiceType, TranscriptionService
from services.audio.srt_adjuster import SrtAdjuster
from services.audio.vtt_adjuster import VttAdjuster

class AudioService:

    @staticmethod
    def split_audio(file_path: str, segment_length_ms: int = 600000) -> List[str]:
        song = AudioSegment.from_file(file_path)
        parts = (len(song) + segment_length_ms - 1) // segment_length_ms  # Calculate number of parts
        base, ext = os.path.splitext(file_path)
        audio_format = ext.replace('.', '')

        def export_segment(i: int):
            start = i * segment_length_ms
            part = song[start:start + segment_length_ms]
            part_file_path = f"{base}_part{i}{ext}"
            part.export(part_file_path, format=audio_format if audio_format != 'm4a' else 'ipod')
            return part_file_path

        with ThreadPoolExecutor(max_workers=6) as executor:
            segments = list(executor.map(export_segment, range(parts)))

        return segments

    @staticmethod
    def transcribe_audio(file_path: str, service: TranscriptionService, prompt: str) -> str:
        if os.path.getsize(file_path) > 26214400:  # If file size exceeds 25MB
            segments = AudioService.split_audio(file_path)

            with ThreadPoolExecutor(max_workers=4) as executor:
                futures = {executor.submit(service.transcribe, segment, prompt): i for i, segment in enumerate(segments)}
                transcriptions = [None] * len(segments)

                for future in as_completed(futures):
                    index = futures[future]
                    try:
                        transcriptions[index] = future.result()
                    except Exception as e:
                        logging.error(f"Error transcribing segment {index}: {e}")
                    finally:
                        os.remove(segments[index])  # Clean up the segment file

            return ' '.join(filter(None, transcriptions))
        else:
            return service.transcribe(file_path, prompt)

    @staticmethod
    def adjust_transcript_if_needed(transcription_file_path: str, service_type: TranscriptionServiceType) -> str:
        if service_type == TranscriptionServiceType.OPENAI_SRT:
            adjusted_srt_file_path = transcription_file_path.replace(".srt", "_adjusted.srt")
            srt_adjuster = SrtAdjuster(transcription_file_path, adjusted_srt_file_path)
            srt_adjuster.adjust_timings()
            os.replace(adjusted_srt_file_path, transcription_file_path)  # Replace original with adjusted
            logging.debug(f"Replaced original SRT file with adjusted SRT file: {transcription_file_path}")

        elif service_type == TranscriptionServiceType.OPENAI_VTT:
            adjusted_vtt_file_path = transcription_file_path.replace(".vtt", "_adjusted.vtt")
            vtt_adjuster = VttAdjuster(transcription_file_path, adjusted_vtt_file_path)
            vtt_adjuster.adjust_timings()
            os.replace(adjusted_vtt_file_path, transcription_file_path)  # Replace original with adjusted
            logging.debug(f"Replaced original VTT file with adjusted VTT file: {transcription_file_path}")

        # Return the path to the adjusted transcript
        with open(transcription_file_path, 'r', encoding='utf-8') as file:
            return file.read(), transcription_file_path



----- FILE: services/audio/audio_downloader.py -----
import json
import subprocess
import os
import re
import logging
from typing import Optional
from urllib.parse import urlparse, parse_qs

class AudioDownloader:

    @staticmethod
    def get_video_info(url: str) -> dict:
        command = ['yt-dlp', '--dump-json', url]
        try:
            result = subprocess.run(command, check=True, capture_output=True, text=True)
            return json.loads(result.stdout)
        except Exception as e:
            logging.error(f"Error occurred while trying to get video info: {str(e)}")
            return {"title": "Unknown Title", "duration": 0, "url": url}

    @staticmethod
    def download_audio(url: str, path: str, max_length_minutes: Optional[int] = None) -> Optional[str]:
        logging.debug(f"Downloading audio from {url} to {path}")

        os.makedirs(path, exist_ok=True)

        command = [
            'yt-dlp', '-x', '--audio-format', 'm4a',
            '--output', os.path.join(path, '%(title)s.%(ext)s'),
            '--format', 'bestaudio', '-N', '4', url
        ]

        try:
            result = subprocess.run(command, check=True, capture_output=True, text=True)
            file_path_match = re.search(r'Destination:\s+(.*\.m4a)', result.stdout)
            
            if file_path_match:
                file_path = file_path_match.group(1).strip()
                if max_length_minutes:
                    trimmed_file_path = file_path.replace('.m4a', '_trimmed.m4a')
                    subprocess.run(['ffmpeg', '-i', file_path, '-ss', '00:00:00', '-t', f'{max_length_minutes * 60}', trimmed_file_path], check=True)
                    os.remove(file_path)
                    return trimmed_file_path
                return file_path
            logging.error("File path not found in yt-dlp output")
        except subprocess.CalledProcessError as e:
            logging.error(f"Error: {e.stderr}")
        return None

    @staticmethod
    def download_vimeo_video(url: str, path: str, max_length_minutes: Optional[int] = None) -> Optional[str]:
        logging.debug(f"Processing Vimeo URL: {url}")
        
        vimeo_dir = os.path.join(path, 'vimeo')
        os.makedirs(vimeo_dir, exist_ok=True)

        command = [
            'yt-dlp',
            '--output', os.path.join(vimeo_dir, '%(title)s.%(ext)s'),
            '--format', 'bestvideo+bestaudio/best',  # Download best video and audio format available
            url
        ]

        try:
            result = subprocess.run(command, check=True, capture_output=True, text=True)
            output = result.stdout
            
            downloaded_files = os.listdir(vimeo_dir)
            if downloaded_files:
                video_file_path = os.path.join(vimeo_dir, downloaded_files[0])
                
                # Convert the video file to audio
                audio_file_name = os.path.splitext(os.path.basename(video_file_path))[0] + '_audio.m4a'
                audio_dir = os.path.join(path, 'audio')
                os.makedirs(audio_dir, exist_ok=True)
                audio_file_path = os.path.join(audio_dir, audio_file_name)
                
                subprocess.run(['ffmpeg', '-i', video_file_path, '-vn', '-ar', '16000', '-ac', '1', '-ab', '128k', '-f', 'ipod', audio_file_path], check=True)
                os.remove(video_file_path)  # Delete the original video file

                if max_length_minutes:
                    trimmed_file_path = audio_file_path.replace('.m4a', '_trimmed.m4a')
                    subprocess.run(['ffmpeg', '-i', audio_file_path, '-ss', '00:00:00', '-t', f'{max_length_minutes * 60}', trimmed_file_path], check=True)
                    os.remove(audio_file_path)
                    return trimmed_file_path

                return audio_file_path
            else:
                logging.error("No files were downloaded.")
        except subprocess.CalledProcessError as e:
            logging.error(f"Error downloading video from Vimeo: {e.stderr}")
        
        return None

    @staticmethod
    def download_google_drive_video(url: str, path: str, max_length_minutes: Optional[int] = None) -> Optional[str]:
        logging.debug(f"Processing Google Drive URL: {url}")
        
        parsed_url = urlparse(url)
        file_id = None

        if 'drive.google.com' in parsed_url.netloc:
            if '/file/d/' in parsed_url.path:
                file_id = parsed_url.path.split('/')[3]
            elif 'id=' in parsed_url.query:
                query_params = parse_qs(parsed_url.query)
                file_id = query_params.get('id', [None])[0]
            else:
                logging.error("Invalid Google Drive URL")
                return None
        else:
            logging.error("Invalid Google Drive URL")
            return None

        if not file_id:
            logging.error("File ID could not be extracted.")
            return None

        direct_link = f"https://drive.google.com/uc?export=download&id={file_id}"
        
        google_dir = os.path.join(path, 'google')
        os.makedirs(google_dir, exist_ok=True)

        command = [
            'yt-dlp',
            '--output', os.path.join(google_dir, '%(title)s.%(ext)s'),
            '--format', 'bestvideo+bestaudio/best',
            direct_link
        ]

        try:
            result = subprocess.run(command, check=True, capture_output=True, text=True)
            downloaded_files = os.listdir(google_dir)
            if downloaded_files:
                video_file_path = os.path.join(google_dir, downloaded_files[0])
                
                # Convert the video file to audio
                audio_file_name = os.path.splitext(os.path.basename(video_file_path))[0] + '_audio.m4a'
                audio_dir = os.path.join(path, 'audio')
                os.makedirs(audio_dir, exist_ok=True)
                audio_file_path = os.path.join(audio_dir, audio_file_name)
                
                subprocess.run(['ffmpeg', '-i', video_file_path, '-vn', '-ar', '16000', '-ac', '1', '-ab', '128k', '-f', 'ipod', audio_file_path], check=True)
                os.remove(video_file_path)  # Delete the original video file

                if max_length_minutes:
                    trimmed_file_path = audio_file_path.replace('.m4a', '_trimmed.m4a')
                    subprocess.run(['ffmpeg', '-i', audio_file_path, '-ss', '00:00:00', '-t', f'{max_length_minutes * 60}', trimmed_file_path], check=True)
                    os.remove(audio_file_path)
                    return trimmed_file_path

                return audio_file_path
            else:
                logging.error("No files were downloaded.")
        except subprocess.CalledProcessError as e:
            logging.error(f"Error downloading video from Google Drive: {e.stderr}")
        
        return None


